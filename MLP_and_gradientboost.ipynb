{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LncSwCnb1sh",
        "outputId": "10d669e8-6369-4011-9402-cd305deefe4e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        bug_id                                            summary  severity\n",
            "0      1143402  Firefox claims to be not the default browser w...    normal\n",
            "1      1143405  Background of html and body element are not ap...    normal\n",
            "2      1143409  Mouse input breaks after using window.showModa...    normal\n",
            "3      1143411  Build failure with next freetype version/curre...    normal\n",
            "4      1143417  HTML element is not treated as root inside for...    normal\n",
            "...        ...                                                ...       ...\n",
            "86089  1426166      Crash in bool IsAboutToBeFinalizedInternal<T>  critical\n",
            "86090  1426171  Potential crash if GraphRate is greater than 4...    normal\n",
            "86091  1426173  Crash in <name omitted> | decltype JS::Dispatc...    normal\n",
            "86092  1426174  Crash in xul.dll@0x28145fa | xul.dll@0x3c748ff...  critical\n",
            "86093  1426176  No symbols for clang_rt.asan_dynamic-x86_64.dl...    normal\n",
            "\n",
            "[86094 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#####  MLP CLASSIFIER WITH 10 HIDDEN LAYERS  #####\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Create a pipeline to vectorize the text data and train an MLP classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(), MLPClassifier(hidden_layer_sizes=(10,), max_iter=10, random_state=42))\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = pipeline.predict(X_test)\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_mlp.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######   GRADIENT BOOST  ######\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Create a pipeline to vectorize the text data and train a Gradient Boosting classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(), GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = pipeline.predict(X_test)\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_gradientboost.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCcnYB8WuHDe",
        "outputId": "fea9ee7d-a176-43c2-9194-748397251763",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        bug_id                                            summary  severity\n",
            "0      1143402  Firefox claims to be not the default browser w...    normal\n",
            "1      1143405  Background of html and body element are not ap...    normal\n",
            "2      1143409  Mouse input breaks after using window.showModa...    normal\n",
            "3      1143411  Build failure with next freetype version/curre...    normal\n",
            "4      1143417  HTML element is not treated as root inside for...    normal\n",
            "...        ...                                                ...       ...\n",
            "86089  1426166      Crash in bool IsAboutToBeFinalizedInternal<T>  critical\n",
            "86090  1426171  Potential crash if GraphRate is greater than 4...  critical\n",
            "86091  1426173  Crash in <name omitted> | decltype JS::Dispatc...  critical\n",
            "86092  1426174  Crash in xul.dll@0x28145fa | xul.dll@0x3c748ff...  critical\n",
            "86093  1426176  No symbols for clang_rt.asan_dynamic-x86_64.dl...    normal\n",
            "\n",
            "[86094 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####  MLP CLASSIFIER WITH 100 HIDDEN LAYERS  #####\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Create a pipeline to vectorize the text data and train an MLP classifier\n",
        "pipeline = make_pipeline(TfidfVectorizer(), MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42))\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = pipeline.predict(X_test)\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "test_data.drop(columns=['summary'], inplace=True)\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_mlp.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ],
      "metadata": {
        "id": "vjEEHudDJ0SE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}