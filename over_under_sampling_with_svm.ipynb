{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ROMs9FC5un9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Define preprocess_text function if not already defined\n",
        "def preprocess_text(text):\n",
        "    # Placeholder preprocessing function, replace with your actual preprocessing logic\n",
        "    return text.lower()\n",
        "\n",
        "# Load training data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test1_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Apply preprocessing\n",
        "train_data['summary_clean'] = train_data['summary'].apply(preprocess_text)\n",
        "test1_data['summary_clean'] = test1_data['summary'].apply(preprocess_text)\n",
        "\n",
        "# Vectorize the text data\n",
        "tfidf = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = tfidf.fit_transform(train_data['summary_clean'])\n",
        "X_test1_tfidf = tfidf.transform(test1_data['summary_clean'])\n",
        "\n",
        "# Apply NearMiss undersampling to the majority class\n",
        "nm1 = NearMiss(version=1)\n",
        "X_undersampled, y_undersampled = nm1.fit_resample(X_train_tfidf, train_data['severity'])\n",
        "\n",
        "# Apply SMOTE oversampling to the undersampled data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_undersampled, y_undersampled)\n",
        "\n",
        "# Divide the resampled data into train and validation sets\n",
        "X_train_resampled, X_validation, y_train_resampled, y_validation = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train SVM model with the best parameters\n",
        "best_svm = SVC(C=1, gamma=0.01, kernel='linear', probability=True)\n",
        "best_svm.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Predict severity labels for validation data\n",
        "y_pred_validation = best_svm.predict(X_validation)\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "precision = precision_score(y_validation, y_pred_validation, average='weighted')\n",
        "recall = recall_score(y_validation, y_pred_validation, average='weighted')\n",
        "f1 = f1_score(y_validation, y_pred_validation, average='weighted')\n",
        "accuracy = accuracy_score(y_validation, y_pred_validation)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Predict severity labels for test data\n",
        "test_predictions = best_svm.predict(X_test1_tfidf)\n",
        "\n",
        "# Create a DataFrame with bug_id and predicted severity\n",
        "final_predictions = pd.DataFrame({\n",
        "    'bug_id': test1_data['bug_id'],\n",
        "    'severity': test_predictions\n",
        "})\n",
        "\n",
        "# Save the final predictions to a CSV file\n",
        "final_predictions.to_csv('final_predictions.csv', index=False)"
      ]
    }
  ]
}