{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ROMs9FC5un9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = pd.read_csv('bugs-train.csv')\n",
        "test_data = pd.read_csv('bugs-test.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = train_data['summary']\n",
        "y_train = train_data['severity']\n",
        "X_test = test_data['summary']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Split the training data for validation\n",
        "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Transform the training and validation data\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_split)\n",
        "X_val_tfidf = tfidf.transform(X_val_split)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Define base models\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define the stacking classifier\n",
        "estimators = [\n",
        "    ('log_reg', log_reg),\n",
        "    ('rf', rf),\n",
        "    ('gb', gb)\n",
        "]\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(max_iter=1000, random_state=42)\n",
        ")\n",
        "\n",
        "# Train the stacking classifier\n",
        "stacking_clf.fit(X_train_tfidf, y_train_split)\n",
        "\n",
        "# Validate the model\n",
        "y_val_pred = stacking_clf.predict(X_val_tfidf)\n",
        "print(classification_report(y_val_split, y_val_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Train the stacking classifier on the full training data\n",
        "X_train_full_tfidf = tfidf.fit_transform(X_train)\n",
        "stacking_clf.fit(X_train_full_tfidf, y_train_encoded)\n",
        "\n",
        "# Predict the severity of the bugs in the test data\n",
        "y_test_pred_encoded = []\n",
        "\n",
        "# Initialize tqdm for progress bar\n",
        "with tqdm(total=len(X_test), desc=\"Processing\", mininterval=0.1) as progress_bar:\n",
        "    for text in X_test:\n",
        "        encoded_pred = stacking_clf.predict([text])\n",
        "        y_test_pred_encoded.append(encoded_pred[0])\n",
        "        progress_bar.update(1)  # Update progress bar\n",
        "\n",
        "# Decode the predictions\n",
        "y_test_pred = label_encoder.inverse_transform(y_test_pred_encoded)\n",
        "\n",
        "# Add the predictions to the test data\n",
        "test_data['severity'] = y_test_pred\n",
        "\n",
        "# Delete the \"summary\" column\n",
        "test_data.drop(columns=['summary'], inplace=True)\n",
        "\n",
        "# Save the predictions to a new CSV file\n",
        "test_data.to_csv('bugs-test-predictions_mlp.csv', index=False)\n",
        "\n",
        "print(test_data)"
      ]
    }
  ]
}